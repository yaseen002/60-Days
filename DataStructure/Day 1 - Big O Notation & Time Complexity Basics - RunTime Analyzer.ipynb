{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db04053-ecd7-4035-aa21-c1f1af2bf8ea",
   "metadata": {},
   "source": [
    "# Big O Notation & Time Complexity Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac264ed-b906-4e53-8509-ce5e3cdd982d",
   "metadata": {},
   "source": [
    "----------------------\n",
    "----------------------\n",
    "\n",
    "## Task 1: Understanding what is Algorithm & why efficiency matters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22a3e7-577e-49f2-8abf-a91216e68b31",
   "metadata": {},
   "source": [
    "### What is an Algorithm?\n",
    "\n",
    "An algorithm is a step-by-step procedure or set of rules to solve a specific problem or perform a task. In the context of programming and Data Structures and Algorithms (DSA), it’s a well-defined sequence of instructions that, when executed, produces a solution to a problem in a finite amount of time. Think of it like a recipe for cooking: you follow specific steps (e.g., chop vegetables, boil water, mix ingredients) to achieve the desired outcome (a dish).\n",
    "\n",
    "In Python, an algorithm is typically implemented as a function or a series of code statements. For example, a simple algorithm to find the maximum number in a list might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86abb0d4-3c5c-4723-816d-264bc1783f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(numbers):\n",
    "    max_num = numbers[0]\n",
    "    for num in numbers:\n",
    "        if num > max_num:\n",
    "            max_num = num\n",
    "    return max_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7395a-9daf-49e6-94d6-cba186c7cd8b",
   "metadata": {},
   "source": [
    "This algorithm iterates through a list to find the largest number by comparing each element with the current maximum.\n",
    "\n",
    "#### Key characteristics of an algorithm:\n",
    "\n",
    "- Input: It takes zero or more inputs (e.g., a list of numbers).\n",
    "- Output: It produces at least one output (e.g., the maximum number).\n",
    "- Definiteness: Each step is clear and unambiguous.\n",
    "- Finiteness: It terminates after a finite number of steps.\n",
    "- Effectiveness: Each step is basic enough to be executed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a7e087-85c5-4dc1-839a-33dde06b30e2",
   "metadata": {},
   "source": [
    "### Why Efficiency Matters\n",
    "\n",
    "Efficiency in algorithms refers to how effectively an algorithm uses computational resources, primarily time (how fast it runs) and space (how much memory it uses). In DSA, efficiency is critical because it directly impacts the performance of your program, especially when dealing with large datasets or real-time applications.\n",
    "\n",
    "#### 1. Time Efficiency (Time Complexity)\n",
    "Time efficiency measures how the runtime of an algorithm grows as the input size increases. This is often expressed using Big-O notation (e.g., O(n), O(n²), O(log n)), which describes the worst-case scenario for the algorithm’s execution time.\n",
    "\n",
    "##### Why it matters:\n",
    "\n",
    "- **Scalability:** An inefficient algorithm may work fine for small inputs but become unbearably slow for large ones. For example, sorting 10 numbers with a slow algorithm might take milliseconds, but sorting 1 million numbers could take hours.\n",
    "- **User Experience:** In applications like web servers, mobile apps, or games, slow algorithms can lead to lag, timeouts, or crashes, frustrating users.\n",
    "- **Cost:** In cloud computing, longer runtimes mean higher costs for CPU usage.\n",
    "\n",
    "##### Example: Consider two algorithms for sorting a list:\n",
    "\n",
    "- **Bubble Sort** (O(n²)): Compares and swaps adjacent elements repeatedly. For a list of 1,000 elements, it might perform ~1,000,000 comparisons.\n",
    "- **Quick Sort** (O(n log n)): Divides the list into smaller parts and sorts them efficiently. For the same 1,000 elements, it might perform ~10,000 comparisons—a huge improvement.\n",
    "\n",
    "Here’s a Python example comparing their performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc370eda-196b-421a-b7c5-d4453130cd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bubble Sort took: 6.0296 seconds\n",
      "Quick Sort took: 0.0017 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def bubble_sort(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        for j in range(0, n-i-1):\n",
    "            if arr[j] > arr[j+1]:\n",
    "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
    "    return arr\n",
    "\n",
    "# Python's built-in sorted() uses Timsort, similar to Quick Sort\n",
    "def quick_sort(arr):\n",
    "    return sorted(arr)\n",
    "\n",
    "# Test with a large list\n",
    "import random\n",
    "arr = [random.randint(1, 1000) for _ in range(10000)]\n",
    "\n",
    "start = time.time()\n",
    "bubble_sort(arr.copy())\n",
    "print(f\"Bubble Sort took: {time.time() - start:.4f} seconds\")\n",
    "\n",
    "start = time.time()\n",
    "quick_sort(arr.copy())\n",
    "print(f\"Quick Sort took: {time.time() - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4591960b-e8a1-43d9-bfff-f8bc2eb6ab3c",
   "metadata": {},
   "source": [
    "#### 2. Space Efficiency (Space Complexity)\n",
    "\n",
    "Space efficiency measures how much memory an algorithm uses, including both the memory for variables (auxiliary space) and the input data. It’s also expressed in Big-O notation.\n",
    "\n",
    "##### Why it matters:\n",
    "\n",
    "- **Limited Resources:** Devices like smartphones or embedded systems have limited memory, so algorithms that use less space are preferred.\n",
    "- **Scalability:** In big data applications, excessive memory usage can crash a program or require expensive hardware.\n",
    "- **Trade-offs:** Sometimes, improving time efficiency increases memory usage (e.g., using a hash table for faster lookups). Understanding this trade-off is key in DSA.\n",
    "\n",
    "\n",
    "\n",
    "##### Example: Consider two ways to compute the Fibonacci sequence:\n",
    "\n",
    "- **Iterative Approach (O(1) space):** Uses a few variables to store the last two numbers.\n",
    "- **Recursive Approach (O(n) space):** Uses the call stack for each recursive call, consuming more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a93a79-b22b-4945-aaba-ef88d5ae1f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterative Fibonacci(35): 9227465, Time: 0.0001 seconds\n",
      "Recursive Fibonacci(35): 9227465, Time: 2.0905 seconds\n"
     ]
    }
   ],
   "source": [
    "# Iterative: O(1) space\n",
    "def fib_iterative(n):\n",
    "    a, b = 0, 1\n",
    "    for _ in range(n):\n",
    "        a, b = b, a + b\n",
    "    return a\n",
    "\n",
    "# Recursive: O(n) space due to call stack\n",
    "def fib_recursive(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib_recursive(n-1) + fib_recursive(n-2)\n",
    "\n",
    "# Test\n",
    "n = 35\n",
    "start = time.time()\n",
    "print(f\"Iterative Fibonacci({n}): {fib_iterative(n)}, Time: {time.time() - start:.4f} seconds\")\n",
    "start = time.time()\n",
    "print(f\"Recursive Fibonacci({n}): {fib_recursive(n)}, Time: {time.time() - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be8b5b2-802a-438e-a94d-79ce80f1471a",
   "metadata": {},
   "source": [
    "The iterative version is faster and uses less memory, especially for large n. The recursive version, while elegant, can cause a stack overflow for large inputs due to excessive memory usage.\n",
    "\n",
    "#### 3. Real-World Implications\n",
    "\n",
    "- **Big Data:** Companies like Google or Amazon process billions of data points. Inefficient algorithms would make search engines, recommendation systems, or databases unusable.\n",
    "Competitive Programming:** In coding competitions, problems often have strict time and memory limits, requiring efficient algorithms to pass test cases.\n",
    "Energy Efficiency:** Inefficient algorithms consume more CPU cycles, increasing energy usage—a concern for data centers and battery-powered devices.\n",
    "\n",
    "#### 4. How to Improve Efficiency in DSA\n",
    "\n",
    "- **Choose the Right Data Structure:** Using a hash table (O(1) lookup) instead of a list (O(n) lookup) can drastically improve performance.\n",
    "- **Optimize Algorithms:** Learn techniques like divide-and-conquer, dynamic programming, or greedy algorithms to reduce time complexity.\n",
    "- **Analyze Trade-offs:** Sometimes, a slightly slower algorithm with lower memory usage is better, depending on the context.\n",
    "- **Profile Code:** Use Python’s time module or profilers to measure performance and identify bottlenecks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad3acb1-7414-48bd-a144-9a28e384c041",
   "metadata": {},
   "source": [
    "----------------------\n",
    "----------------------\n",
    "\n",
    "## Task 2: Learn Big O, Big Θ, Big Ω.\n",
    "\n",
    "These notations are part of asymptotic analysis in DSA, which helps us describe how an algorithm's performance (time or space) scales as the input size grows large. They ignore constant factors and lower-order terms to focus on the dominant behavior. We use a variable like $ n $ to represent the input size (e.g., number of elements in a list).\n",
    "\n",
    "### Big O Notation (O)\n",
    "\n",
    "- **Definition:** Big O describes the upper bound or worst-case scenario for the growth rate of an algorithm's runtime or space usage. It says the algorithm will take at most this much time/space for large inputs.\n",
    "- Mathematical Meaning: A function $ f(n) $ is $ O(g(n)) $ if there exist positive constants $ c $ and $ n_0 $ such that $ f(n) \\leq c \\cdot g(n) $ for all $ n \\geq n_0 $.\n",
    "- Intuition: \"In the worst case, it's no worse than this.\" It's the most commonly used because we care about guarantees in the worst scenario.\n",
    "\n",
    "- Examples:\n",
    "\n",
    "    - **O(1)** (Constant time): Runtime doesn't depend on input size. E.g., accessing an element in a list by index: my_list[0].\n",
    "    - **O(n)** (Linear time): Runtime grows linearly with input size. E.g., iterating through a list once to find a sum.\n",
    "    - **O(n²)** (Quadratic time): Runtime grows with the square of input size. Common in nested loops, like checking all pairs in a list.\n",
    "    - **O(log n)** (Logarithmic time): Runtime grows slowly, halving the problem each step. E.g., binary search on a sorted list.\n",
    "    - **O(2^n)** (Exponential time): Grows very fast, common in recursive brute-force solutions like the naive Fibonacci.\n",
    "\n",
    "### Big Θ Notation (Θ)\n",
    "\n",
    "- **Definition:** Big Theta describes a tight bound, meaning both the upper and lower bounds are the same. It's the exact growth rate (up to a constant factor).\n",
    "- **Mathematical Meaning:** $ f(n) $ is $ \\Theta(g(n)) $ if there exist positive constants $ c_1 $, $ c_2 $, and $ n_0 $ such that $ c_1 \\cdot g(n) \\leq f(n) \\leq c_2 \\cdot g(n) $ for all $ n \\geq n_0 $.\n",
    "- **Intuition:** \"It's exactly this order of growth.\" Use it when the best and worst cases are similar.\n",
    "- **Examples:**\n",
    "\n",
    "    - **Θ(n):** A simple loop that always runs n times, like summing a list—no matter the input, it's linear.\n",
    "    - **Θ(n²):** Bubble sort in average case (though worst is O(n²), average is Θ(n²)).\n",
    "    - **Θ(log n):** Binary search when the list is sorted; it always takes about log n steps\n",
    "\n",
    "### Big Ω Notation (Ω)\n",
    "\n",
    "- **Definition:** Big Omega describes the lower bound or best-case scenario. It says the algorithm will take at least this much time/space.\n",
    "- **Mathematical Meaning:** $ f(n) $ is $ \\Omega(g(n)) $ if there exist positive constants $ c $ and $ n_0 $ such that $ f(n) \\geq c \\cdot g(n) $ for all $ n \\geq n_0 $.\n",
    "- **Intuition:** \"In the best case, it's at least this.\" Useful for proving an algorithm can't be faster than a certain rate.\n",
    "- **Examples:**\n",
    "\n",
    "    - **ΘΩ(1):** Any algorithm has at least constant time (e.g., even if early exit, it does some work).\n",
    "    - **ΘΩ(n):** Sorting algorithms like merge sort can't be faster than linear in the best case because you must look at all elements.\n",
    "    - **ΘΩ(log n): Searching in a balanced binary search tree; you can't do better than log n comparisons in the best case for large n.\n",
    "\n",
    "### Comparison Table\n",
    "\n",
    "| Notation | Bound Type | When to Use | Example Algorithm |\n",
    "|----------|------------|-------------|-------------------|\n",
    "| Big O (O) | Upper (Worst-case) | Guaranteeing max performance | Linear search: O(n) worst-case |\n",
    "| Big Θ (Θ) | Tight (Average/Exact) | When bounds match | Quick sort average: Θ(n log n) |\n",
    "| Big Ω (Ω) | Lower (Best-case) | Proving minimum requirements | Any comparison-based sort: Ω(n log n) |\n",
    "\n",
    "\n",
    "### Key Notes:\n",
    "\n",
    "- We often simplify to Big O in practice because it's conservative.\n",
    "- Common orders (from best to worst): O(1) < O(log n) < O(n) < O(n log n) < O(n²) < O(2^n) < O(n!).\n",
    "- In Python, these help choose algorithms: Use O(log n) binary search (bisect module) over O(n) linear search for large sorted lists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1817f47f-342a-4681-962d-1d6b570be1c7",
   "metadata": {},
   "source": [
    "----------------------\n",
    "----------------------\n",
    "## Task 3: Analyze time complexity of simple loops.\n",
    "\n",
    "Time complexity analysis for loops involves counting how many times the inner operations execute relative to input size $ n $. Ignore constants and focus on the dominant term. We assume each basic operation (e.g., assignment, comparison) takes constant time.\n",
    "\n",
    "### Steps to Analyze:\n",
    "\n",
    "1. Identify the input size $ n $ (e.g., length of a list).\n",
    "2. Count loop iterations: A single loop from 1 to n is O(n).\n",
    "3. For nested loops, multiply iterations: Outer loop n times, inner n times → O(n²).\n",
    "4. Consider conditions: If a loop runs a fixed number of times (independent of n), it's O(1).\n",
    "5. Drop constants and non-dominant terms: 3n + 5 → O(n); n² + n → O(n²).\n",
    "\n",
    "- #### Examples in Python\n",
    "\n",
    "    1. #### Single Loop (O(n)):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c60603c-6df0-4728-b55d-a4a819bb672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_list(arr):\n",
    "    total = 0\n",
    "    for num in arr:  # Runs n times\n",
    "        total += num  # Constant time per iteration\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91a3652-853e-405c-b70e-aa49191dc966",
   "metadata": {},
   "source": [
    "\n",
    "    - Analysis: The loop executes n times, each with O(1) work → Total: O(n).\n",
    "    - Reasoning: As n doubles, runtime roughly doubles.\n",
    "\n",
    " #### 2. Nested Loops (O(n²)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62eee4c-b2e8-4d16-83e6-0efe52ead6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pairs(arr):\n",
    "    for i in range(len(arr)):  # Outer: n times\n",
    "        for j in range(len(arr)):  # Inner: n times per outer\n",
    "            print(arr[i], arr[j])  # O(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a5a9a0-d1ad-4e75-86e5-e4ff11f53ed7",
   "metadata": {},
   "source": [
    "- Analysis: Outer loop: n iterations; each triggers n inner iterations → n * n = n² → O(n²).\n",
    "- Reasoning: For n=10, ~100 operations; for n=100, ~10,000—scales quadratically.\n",
    "\n",
    "#### 3. Loop with Fixed Iterations (O(1)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19faff4-7c84-4c3d-b966-b469bb98e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_ten():\n",
    "    for i in range(10):  # Fixed 10 times, not dependent on n\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e8f450-ee1f-4a3b-b5dc-ed01abde5079",
   "metadata": {},
   "source": [
    "- Analysis: Runs a constant 10 times → O(1), even if called with large input.\n",
    "- Reasoning: Runtime doesn't grow with n.\n",
    "\n",
    "\n",
    "#### 4. Loop with Halving (O(log n)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beefb93-5850-472a-bf41-066bf57f9d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(arr, target):\n",
    "    low, high = 0, len(arr) - 1\n",
    "    while low <= high:  # Loop halves search space each time\n",
    "        mid = (low + high) // 2\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            high = mid - 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87643138-87d4-4bfb-8509-1080022cd0e4",
   "metadata": {},
   "source": [
    "- Analysis: Each iteration halves the range (from n to n/2 to n/4...). Number of iterations: log₂(n) → O(log n).\n",
    "- Reasoning: For n=1024, max ~10 iterations (2¹⁰=1024); for n=1,048,576, ~20 iterations.\n",
    "\n",
    "\n",
    "#### 5. Multiple Independent Loops (O(n)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3883b171-da28-48a8-a207-a905c84eaf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_loops(arr):\n",
    "    for num in arr:  # O(n)\n",
    "        print(num)\n",
    "    for num in arr:  # Another O(n)\n",
    "        print(num * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a3a0a-d651-49a5-a093-caca1d17ed87",
   "metadata": {},
   "source": [
    "- Analysis: O(n) + O(n) = O(2n) → Drop constant: O(n).\n",
    "- Reasoning: Sequential additions don't multiply; dominant is still linear.\n",
    "\n",
    "**Tips:** Use Python's time module to empirically verify (as in previous examples), but asymptotic analysis is theoretical. For complex loops, sum series (e.g., for i in 1 to n: inner j=1 to i → O(n²) since sum= n(n+1)/2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ce0d5-c1f9-48d1-a38b-6c5bef34bfe1",
   "metadata": {},
   "source": [
    "----------------------\n",
    "----------------------\n",
    "## Task 4: Space Complexity basics.\n",
    "\n",
    "Space complexity measures how much memory an algorithm uses relative to input size $ n $, excluding the input itself (we focus on auxiliary space like variables, data structures). Like time, it's expressed in Big O notation.\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "- **Constant Space (O(1)):** Uses a fixed amount of memory, regardless of n. E.g., a few variables.\n",
    "- **Linear Space (O(n)):** Memory grows linearly, like creating a new list of size n.\n",
    "- **Quadratic Space (O(n²)):** E.g., a 2D matrix of n x n.\n",
    "- **Factors:** Includes recursion stack (each call uses space), arrays, hash tables.\n",
    "- **Trade-offs:** Sometimes low space means higher time (e.g., in-place sorting uses O(1) extra space but may be slower).\n",
    "\n",
    "### Examples in Python\n",
    "\n",
    "#### 1. O(1) Space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4648ba29-fd94-4331-b4b6-7e02ab632b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_list(arr):\n",
    "    total = 0  # Single variable\n",
    "    for num in arr:\n",
    "        total += num\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9663df-9d2f-43a0-b1df-df8c4790cd12",
   "metadata": {},
   "source": [
    "- Analysis: Only 'total' (constant) + loop doesn't allocate extra → O(1).\n",
    "- Reasoning: Memory usage doesn't increase with larger arr.\n",
    "\n",
    "\n",
    "#### 2. O(n) Space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62731c-3f95-407a-a10c-98cdfebf454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_list(arr):\n",
    "    reversed_arr = []  # New list of size n\n",
    "    for i in range(len(arr)-1, -1, -1):\n",
    "        reversed_arr.append(arr[i])\n",
    "    return reversed_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a850de1-a014-4106-938d-adac52908502",
   "metadata": {},
   "source": [
    "- Analysis: Creates a new list of n elements → O(n).\n",
    "- Reasoning: Doubles memory for large n; Python lists are dynamic arrays.\n",
    "\n",
    "\n",
    "#### 3. O(n²) Space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb0fe0-c9cb-4b00-a354-d3a63fe53541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(n):\n",
    "    matrix = [[0 for _ in range(n)] for _ in range(n)]  # n rows, each with n elements\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9f6fa-0602-4271-94c9-dd984e872d05",
   "metadata": {},
   "source": [
    "- Analysis: n * n = n² elements → O(n²).\n",
    "- Reasoning: For n=1000, ~1 million integers (~4MB); scales poorly.\n",
    "\n",
    "\n",
    "#### 4. Recursive Space (O(n)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2690f-3173-4954-90bd-41275e915a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    return n * factorial(n-1)  # Recursion depth n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a61d57-7a03-45c7-b820-2a2ce60998ab",
   "metadata": {},
   "source": [
    "- Analysis: Call stack holds n frames (each with variables) → O(n).\n",
    "- Reasoning: Python has recursion limit (~1000); deep recursion can cause stack overflow.\n",
    "\n",
    "\n",
    "\n",
    "**Tips:** Optimize by reusing space (e.g., in-place algorithms like sorting without extra arrays). In Python, immutable types (e.g., strings) may create hidden copies, increasing space. Always consider if you can stream data instead of storing everything."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57232e6f-e333-4b76-b229-c5eb52c767b5",
   "metadata": {},
   "source": [
    "----------------------\n",
    "----------------------\n",
    "\n",
    "## Practice LeetCode Problem: Two Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb7fc92-5b17-4bd2-ab8e-2cfe50e6a2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Solution:\n",
    "    def twoSum(self, nums, target):\n",
    "      hash_map = {}\n",
    "      for i,n in enumerate(nums):\n",
    "        diff = target - n\n",
    "        if diff in hash_map:\n",
    "          return [hash_map[diff], i]\n",
    "        hash_map[n] = i\n",
    "      \n",
    "nums = [2,7,11,15]\n",
    "target = 9\n",
    "sol = Solution()\n",
    "print(sol.twoSum(nums, target)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2727c30-c4e0-4985-85af-90150d4949f1",
   "metadata": {},
   "source": [
    "----------------------\n",
    "----------------------\n",
    "\n",
    "## Project: Runtime Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38c420c0-5b52-4559-a0a8-f483ad0faff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Size | Execution Time (seconds)\n",
      "--------------------------------\n",
      "      100 | 0.000004\n",
      "     1000 | 0.000031\n",
      "    10000 | 0.000606\n",
      "   100000 | 0.004706\n",
      "  1000000 | 0.030974\n"
     ]
    }
   ],
   "source": [
    "# TODO 1 => Import necessary modules (time for measuring execution time, random for generating test data)\n",
    "import time\n",
    "import random\n",
    "\n",
    "# TODO 2 => Define a sample function to analyze (e.g., sum of numbers in a list)\n",
    "def sum_numbers(arr):\n",
    "    total = 0\n",
    "    for num in arr:\n",
    "        total += num\n",
    "    return total\n",
    "\n",
    "# TODO 3 => Create a function to generate test data of varying sizes\n",
    "def generate_test_data(size):\n",
    "    return [random.randint(1, 100) for _ in range(size)]\n",
    "\n",
    "# TODO 4 => Create the runtime analyzer to measure execution time for different input sizes\n",
    "def runtime_analyzer(func, input_size):\n",
    "    print(\"Input Size | Execution Time (seconds)\")\n",
    "    print(\"-------------------------------------\")\n",
    "    for size in input_size:\n",
    "        # Generate test data\n",
    "        data = generate_test_data(size)\n",
    "        # Measure start time\n",
    "        start_time = time.time()\n",
    "        # Execute the function\n",
    "        func(data)\n",
    "        # Measure the End Time\n",
    "        end_time = time.time()\n",
    "        # Calculate the execution time\n",
    "        exec_time = end_time - start_time\n",
    "        print(f\"{size: 9d} | {exuc_time:.6f}\")\n",
    "        \n",
    "# Main Execution\n",
    "if __name__ == '__main__':\n",
    "    # Define the input size to test (e.g 100, 1000, 10000, 100000, 1000000)\n",
    "    input_size = [100, 1000, 10000, 100000, 1000000]\n",
    "    # Run the Analyzer on the sum_numbers function\n",
    "    analyze_runtime(sum_numbers, input_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
