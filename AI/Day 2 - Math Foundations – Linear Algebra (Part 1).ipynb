{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ce25ae-6526-4b11-9663-00c3ff87f881",
   "metadata": {},
   "source": [
    "# Math Foundations – Linear Algebra (Part 1)\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f63ec1d-61be-4c55-bebf-b9622c391a51",
   "metadata": {},
   "source": [
    "## Task 1: Scalars, Vectors, Matrices Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa7e69-368b-4dbf-a751-269d4af5aa1c",
   "metadata": {},
   "source": [
    "### Scalars\n",
    "\n",
    "- Definition: A scalar is a single number, representing a quantity with magnitude but no direction. It’s a 0-dimensional entity.\n",
    "\n",
    "- Examples:\n",
    "\n",
    "    - A temperature reading: 25 (e.g., 25°C).\n",
    "    - A learning rate in ML: 0.01.\n",
    "    - Any real number (integer, float, etc.), like 3, -7.5, or π.\n",
    "\n",
    "- Role in AI/ML: Scalars are used for parameters (e.g., weights in neural networks) or loss values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aebe9df-94d1-4361-abed-820c6d29eb62",
   "metadata": {},
   "source": [
    "### Vectors\n",
    "\n",
    "- Definition: A vector is an ordered list of numbers (scalars), representing a quantity with magnitude and direction. It’s a 1-dimensional array, often visualized as a point in space or an arrow.\n",
    "\n",
    "- Examples:\n",
    "\n",
    "    - A 2D vector: [3, 4] (e.g., representing a point in a 2D plane).\n",
    "    - A feature vector in ML: [0.5, 1.2, 3.7] (e.g., representing features like height, weight, age).\n",
    "\n",
    "- Notation: Written as a column or row, e.g.,\n",
    "$$\\vec{v} = \\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix} \\text{(column vector)} \\quad \\text{or} \\quad \\vec{v} = [3, 4] \\text{(row vector)}.$$\n",
    "\n",
    "- Role in AI/ML: Vectors represent data points, model weights, or gradients in algorithms like gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10328e42-0c91-4c6f-86aa-42bfebdaf3ae",
   "metadata": {},
   "source": [
    "### Matrices\n",
    "\n",
    "- Definition: A matrix is a 2-dimensional array of numbers, organized in rows and columns. It’s used to represent relationships or transformations.\n",
    "- Examples:\n",
    "\n",
    "    - A 2x3 matrix (2 rows, 3 columns):\n",
    "$$A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{bmatrix}$$\n",
    "\n",
    "    - An image in ML: A 28x28 grayscale image can be a 28x28 matrix of pixel intensities.\n",
    "\n",
    "- Notation: Denoted as $ A_{m \\times n} $, where $ m $ is the number of rows and $ n $ is the number of columns.\n",
    "\n",
    "- Role in AI/ML: Matrices represent datasets, weight matrices in neural networks, or transformations (e.g., rotations in image processing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46543154-92e6-4997-ab9a-3180bbdd7732",
   "metadata": {},
   "source": [
    "### Intuition\n",
    "\n",
    "- Scalar: A single value, like a weight or score.\n",
    "- Vector: A list of values, like coordinates or features of a data point.\n",
    "- Matrix: A grid of values, like a table of data or a neural network layer’s weights.\n",
    "- In ML, datasets are often matrices (rows = samples, columns = features), vectors are individual data points, and scalars are used for calculations like loss or learning rates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19960674-1aac-4aa0-8d79-87ad2bd006fa",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Task 2: Matrix Addition, Scalar Multiplication\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bf7652-3d1d-4e58-833f-6e1d49f691ef",
   "metadata": {},
   "source": [
    "### Matrix Addition\n",
    "\n",
    "- Adding two matrices involves adding their corresponding elements. Matrices must have the same dimensions (same number of rows and columns).\n",
    "\n",
    "- Rule: For matrices $ A $ and $ B $, both of size $ m \\times n $, the sum $ C = A + B $ is:\n",
    "$$C_{ij} = A_{ij} + B_{ij}$$\n",
    "where $ C_{ij} $ is the element in the $ i $-th row and $ j $-th column.\n",
    "\n",
    "- Example:\n",
    "$$A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 5 & 6 \\\\ 7 & 8 \\end{bmatrix}$$\n",
    "$$A + B = \\begin{bmatrix} 1+5 & 2+6 \\\\ 3+7 & 4+8 \\end{bmatrix} = \\begin{bmatrix} 6 & 8 \\\\ 10 & 12 \\end{bmatrix}$$\n",
    "\n",
    "- Role in AI/ML: Used in operations like combining feature matrices or updating weights in neural networks.\n",
    "\n",
    "#### Python Implementation: Use NumPy’s np.array for matrices and the + operator for addition.\n",
    "\n",
    "- Steps:\n",
    "\n",
    "    - Import NumPy to handle matrix operations.\n",
    "    - Define two matrices of the same dimensions as NumPy arrays.\n",
    "    - Use the + operator or np.add() to add the matrices.\n",
    "    - Display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe1656d6-3a13-46ef-a1e4-6ba3d49bcf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.3.2-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Downloading numpy-2.3.2-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m44.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:03\u001b[0m0:12\u001b[0m:15\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-2.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef351dd2-5c47-4cdb-abe4-8233479b13b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  8],\n",
       "       [10, 12]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1,2], [3,4]])\n",
    "B = np.array([[5,6], [7,8]])\n",
    "\n",
    "C = A + B\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8877b7b7-0073-4aa8-9723-57826a93d27d",
   "metadata": {},
   "source": [
    "### Scalar Multiplication\n",
    "\n",
    "- Multiplying a matrix by a scalar involves multiplying every element of the matrix by that scalar.\n",
    "- Rule: For a scalar $ k $ and matrix $ A $, the result $ C = kA $ is:\n",
    "$$C_{ij} = k \\cdot A_{ij}$$\n",
    "\n",
    "- Example:\n",
    "$$k = 2, \\quad A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}$$\n",
    "$$kA = 2 \\cdot \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} = \\begin{bmatrix} 2 \\cdot 1 & 2 \\cdot 2 \\\\ 2 \\cdot 3 & 2 \\cdot 4 \\end{bmatrix} = \\begin{bmatrix} 2 & 4 \\\\ 6 & 8 \\end{bmatrix}$$\n",
    "\n",
    "- Role in AI/ML: Scalar multiplication scales weights or features, often used in optimization (e.g., scaling gradients in gradient descent).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10094aa0-9e88-4053-9132-815d9105e3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "\n",
      "Scalar k: 2\n",
      "\n",
      "k * A:\n",
      "[[2 4]\n",
      " [6 8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Define a matrix and a scalar\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "k = 2\n",
    "\n",
    "# Step 2: Perform scalar multiplication\n",
    "C = k * A  # or use np.multiply(k, A)\n",
    "\n",
    "# Step 3: Print the matrix and result\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "print(\"\\nScalar k:\", k)\n",
    "print(\"\\nk * A:\")\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80191356-9c44-41dc-a01d-b75c9c8683c4",
   "metadata": {},
   "source": [
    "### Key Notes\n",
    "\n",
    "- Matrix addition requires matching dimensions; otherwise, it’s undefined.\n",
    "- Scalar multiplication works with any matrix size, as it’s just element-wise scaling.\n",
    "- These operations are foundational for manipulating data in ML algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95bd71e-6a48-48b7-ae33-dd76fe780c2e",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Task 3: Dot Product Intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bdf5ec-46f7-42d4-bb71-72629387e5cf",
   "metadata": {},
   "source": [
    "### Definition\n",
    "\n",
    "- The dot product is an operation between two vectors of the same length, producing a scalar. It measures how aligned or similar two vectors are.\n",
    "\n",
    "- Formula: For vectors $ \\vec{a} = [a_1, a_2, \\dots, a_n] $ and $ \\vec{b} = [b_1, b_2, \\dots, b_n] $, the dot product is:\n",
    "$$\\vec{a} \\cdot \\vec{b} = a_1 b_1 + a_2 b_2 + \\dots + a_n b_n$$\n",
    "\n",
    "- Example:\n",
    "$$\\vec{a} = [1, 2, 3], \\quad \\vec{b} = [4, 5, 6]$$\n",
    "$$\\vec{a} \\cdot \\vec{b} = (1 \\cdot 4) + (2 \\cdot 5) + (3 \\cdot 6) = 4 + 10 + 18 = 32$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a239310-554e-475b-b035-3efbb23e901c",
   "metadata": {},
   "source": [
    "### Geometric Intuition\n",
    "\n",
    "- The dot product reflects the similarity or alignment between two vectors:\n",
    "\n",
    "    - If the vectors point in similar directions, the dot product is positive and large.\n",
    "    - If they’re perpendicular (orthogonal), the dot product is zero.\n",
    "    - If they point in opposite directions, the dot product is negative.\n",
    "\n",
    "\n",
    "- Mathematically:\n",
    "$$\\vec{a} \\cdot \\vec{b} = \\|\\vec{a}\\| \\|\\vec{b}\\| \\cos(\\theta)$$\n",
    "where $ \\|\\vec{a}\\| $ and $ \\|\\vec{b}\\| $ are the magnitudes (lengths) of the vectors, and $ \\theta $ is the angle between them.\n",
    "\n",
    "\n",
    "- Example Visualization:\n",
    "\n",
    "    - For $ \\vec{a} = [1, 0] $, $ \\vec{b} = [0, 1] $ (perpendicular vectors):\n",
    "$$\\vec{a} \\cdot \\vec{b} = (1 \\cdot 0) + (0 \\cdot 1) = 0$$\n",
    "    - This confirms they’re orthogonal (angle = 90°)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e119d42-9143-434f-a9f2-5857f7efdc03",
   "metadata": {},
   "source": [
    "### Role in AI/ML\n",
    "\n",
    "- Neural Networks: The dot product is used in computing weighted sums (e.g., input features × weights) in neurons.\n",
    "- Similarity Measures: In recommendation systems or NLP, dot products measure how similar two feature vectors are (e.g., user preferences vs. item features).\n",
    "- Gradient Descent: Dot products appear in loss functions or when computing gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25ccc0f-4577-4817-970b-0e78703898e8",
   "metadata": {},
   "source": [
    "### Python Implementation\n",
    "\n",
    "Use NumPy’s np.dot() or @ operator for the dot product.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "- Import NumPy.\n",
    "- Define two vectors of the same length as NumPy arrays.\n",
    "- Compute the dot product using np.dot() or @.\n",
    "- Display the result and interpret its meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e98e2f1e-5167-4a79-bc8a-e249a8a57c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector a: [1 2 3]\n",
      "Vector b: [4 5 6]\n",
      "Dot Product (a · b): 32\n",
      "Cosine Similarity: 0.9746318461970762\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Define two vectors of the same length\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "\n",
    "# Step 2: Compute the dot product\n",
    "dot_product = np.dot(a, b)  # or use a @ b\n",
    "\n",
    "# Step 3: Print the vectors and result\n",
    "print(\"Vector a:\", a)\n",
    "print(\"Vector b:\", b)\n",
    "print(\"Dot Product (a · b):\", dot_product)\n",
    "\n",
    "# Step 4: Optional - Compute cosine similarity to show intuition\n",
    "# Cosine similarity = (a · b) / (||a|| * ||b||)\n",
    "norm_a = np.linalg.norm(a)  # Magnitude of a\n",
    "norm_b = np.linalg.norm(b)  # Magnitude of b\n",
    "cosine_similarity = dot_product / (norm_a * norm_b)\n",
    "print(\"Cosine Similarity:\", cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a86913-2232-43f8-9a59-76a2dfd1cf85",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Project: Vector Similarity Checker\n",
    "\n",
    "Input: Two lists of numbers (vectors).\n",
    "\n",
    "Output: Their dot product and cosine similarity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b2791-9b93-4a1d-bc2f-94bc25a5c33d",
   "metadata": {},
   "source": [
    "### How to Do It\n",
    "\n",
    "- **Understand the Inputs:**\n",
    "\n",
    "    - You’ll receive two lists of numbers (vectors) of the same length, e.g., [1, 2, 3] and [4, 5, 6].\n",
    "    - These represent vectors in an n-dimensional space.\n",
    "\n",
    "- **Dot Product:**\n",
    "\n",
    "    - The dot product of two vectors $ \\vec{a} $ and $ \\vec{b} $ is calculated as:\n",
    "$$\\vec{a} \\cdot \\vec{b} = a_1 b_1 + a_2 b_2 + \\dots + a_n b_n$$\n",
    "\n",
    "    - It’s a scalar that measures how much the vectors align.\n",
    "    - In Python, use np.dot() or the @ operator with NumPy arrays.\n",
    "\n",
    "- **Cosine Similarity:**\n",
    "\n",
    "    - Cosine similarity measures the cosine of the angle between two vectors, indicating how similar they are (regardless of magnitude):\n",
    "$$\\text{Cosine Similarity} = \\frac{\\vec{a} \\cdot \\vec{b}}{\\|\\vec{a}\\| \\|\\vec{b}\\|}$$\n",
    "where $ \\|\\vec{a}\\| $ and $ \\|\\vec{b}\\| $ are the Euclidean norms (magnitudes) of the vectors:\n",
    "$$\\|\\vec{a}\\| = \\sqrt{a_1^2 + a_2^2 + \\dots + a_n^2}$$\n",
    "\n",
    "    - Output ranges from -1 (opposite directions) to 1 (same direction), with 0 indicating orthogonality (right angles).\n",
    "    - In Python, compute the dot product and divide by the product of norms using np.linalg.norm().\n",
    "\n",
    "\n",
    "- **Steps to Implement:**\n",
    "\n",
    "    - Import NumPy for efficient vector operations.\n",
    "    - Convert input lists to NumPy arrays.\n",
    "    - Check if vectors have the same length (to avoid errors).\n",
    "    - Compute the dot product.\n",
    "    - Compute the cosine similarity using the dot product and vector norms.\n",
    "    - Handle edge cases (e.g., zero vectors to avoid division by zero).\n",
    "\n",
    "- **AI/ML Relevance:**\n",
    "\n",
    "    - Dot products are used in neural networks for weighted sums.\n",
    "    - Cosine similarity is common in NLP (e.g., comparing word vectors) and recommendation systems (e.g., user-item similarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26b52c53-7332-43db-bb0c-16369d4059c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector 1: [1, 2, 3]\n",
      "Vector 2: [4, 5, 6]\n",
      "Dot Product: 32\n",
      "Cosine Similarity: 0.9746\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vector_similarity_checker(vector1, vector2):\n",
    "    # Todo 1: Convert input lists to NumPy arrays\n",
    "    a = np.array(vector1)\n",
    "    b = np.array(vector2)\n",
    "    \n",
    "    # Todo 2: Check if vectors have the same length\n",
    "    if len(a) != len(b):\n",
    "        raise ValueError('Vectors Must have the same lenght')\n",
    "    \n",
    "    # Todo 3: Compute the dot product\n",
    "    dotProduct = np.dot(a, b)\n",
    "    \n",
    "    # Todo 4: Compute cosine similarity\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "\n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        raise ValueError('Cannot compute cosine similarity with zero vector')\n",
    "    coisine_similarity = dot_product / (norm_a * norm_b)\n",
    "\n",
    "    return dot_product, coisine_similarity\n",
    "\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    vector1 = [1, 2, 3]\n",
    "    vector2 = [4, 5, 6]\n",
    "    dot_prod, cos_sim = vector_similarity_checker(vector1, vector2)\n",
    "    print(f\"Vector 1: {vector1}\")\n",
    "    print(f\"Vector 2: {vector2}\")\n",
    "    print(f\"Dot Product: {dot_prod}\")\n",
    "    print(f\"Cosine Similarity: {cos_sim:.4f}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
